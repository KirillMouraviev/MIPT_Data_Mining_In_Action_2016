{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ: Data Mining in Action (осень, 2016)\n",
    "\n",
    "* Дмитрий Персиянов, <dmitry.persiyanov@gmail.com>, https://vk.com/persiyanov\n",
    "* Арсений Ашуха, <ars.ashuha@gmail.com>, https://vk.com/ars.ashuha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Домашнее задание №1: линейные модели, бустинг</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "\n",
    "*Линейные модели*:\n",
    "- Лекция 2, DMIA: https://goo.gl/luURTu\n",
    "- Логистическая регрессия, UFLDL Tutorial: http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/\n",
    "- Линейная регрессия, UFLDL Tutorial: http://ufldl.stanford.edu/tutorial/supervised/LinearRegression/\n",
    "\n",
    "*Бустинг*:\n",
    "- Hastie, The Elements of Statistical Learning, https://goo.gl/k3wfEU, 10 Boosting and Additive Trees 337\n",
    "- Соколов, Семинары по композиционным методам, https://goo.gl/sn8RyJ, http://goo.gl/ajNTQy\n",
    "\n",
    "\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``datamininginaction@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``DMIA2016_fall <направление> <фамилия>_<имя> HW1``, к примеру -- ``DMIA2016_fall trends ivanov_ilya HW1``\n",
    "\n",
    "**Вопросы**:\n",
    "- Задавайте вопросы в issues на гитхабе: https://github.com/vkantor/MIPT_Data_Mining_In_Action_2016/issues\n",
    "- Либо в группу или нам в личные сообщения: https://vk.com/data_mining_in_action\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Overview</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На последней лекции вы узнали про классические модели машинного обучения, которые каждый Data Scientist должен знать и понимать, как они работают.\n",
    "\n",
    "В этом домашнем задании мы предлагаем вам реализовать две модели: одну линейную -- логистическую регрессию, и модель бустинга над деревьями, а также сравнить их качество на одном датасете.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Part 1: Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm # interactive progress bar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Знакомство с данными\n",
    "Данные представляют собой выборку отзывов о еде с сайта Амазон. Для них проставлены метки -- положительный или отрицательный отзыв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110163, 3)\n"
     ]
    }
   ],
   "source": [
    "print train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.50074\n",
       "1    0.49926\n",
       "Name: Prediction, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Prediction.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что классы сбалансированы. Можем оценивать качество модели по метрике ```accuracy```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reviews_Summary</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239071</td>\n",
       "      <td>Michigan Cherries</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466160</td>\n",
       "      <td>Great Product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>397133</td>\n",
       "      <td>Ovaltine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297146</td>\n",
       "      <td>~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292685</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID    Reviews_Summary  Prediction\n",
       "0  239071  Michigan Cherries           1\n",
       "1  466160      Great Product           1\n",
       "2  397133           Ovaltine           1\n",
       "3  297146                  ~           1\n",
       "4  292685           Love it!           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reviews_Summary</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110158</th>\n",
       "      <td>486256</td>\n",
       "      <td>Terrible!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110159</th>\n",
       "      <td>199050</td>\n",
       "      <td>Cheap Coffee, No Banana Flavor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110160</th>\n",
       "      <td>278179</td>\n",
       "      <td>Not as described</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110161</th>\n",
       "      <td>87500</td>\n",
       "      <td>Tastes like a squirt of toothpaste mixed into ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110162</th>\n",
       "      <td>121963</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                    Reviews_Summary  Prediction\n",
       "110158  486256                                          Terrible!           0\n",
       "110159  199050                     Cheap Coffee, No Banana Flavor           0\n",
       "110160  278179                                   Not as described           0\n",
       "110161   87500  Tastes like a squirt of toothpaste mixed into ...           0\n",
       "110162  121963                                       Disappointed           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## 2. Извлечение признаков\n",
    "Для решения задачи классификации необходимо преобразовать каждый отзыв (документ) в вектор. Размерность данного вектора будет равна количеству слов используемых в корпусе (все документы). Каждая координата соответствует слову, значение в координает равно количеству раз, слово используется в документе. \n",
    "\n",
    "Для решения данной задачи вам необходимо написать код, который преобразовывает матрицу документов в численную матрицу.\n",
    "\n",
    "Дополнительная информация для решения задачи:\n",
    "\n",
    "- Подробнее про векторное представление документов: http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "- Используйте данный трансформер: http://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage\n",
    "- Подробнее про разреженные матрицы: http://docs.scipy.org/doc/scipy-0.14.0/reference/sparse.html\n",
    "- Hashing trick: https://en.wikipedia.org/wiki/Feature_hashing\n",
    "\n",
    "Помните, что все эти трансформеры возвращают ```sparse```-матрицы. Учитывая это и то, что линейные модели достаточно хорошо масштабируются на большое количество фич, можно смело ставить ```n_features``` 1000+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_summaries = list(train_df['Reviews_Summary'].values)\n",
    "review_summaries = [l.lower() for l in review_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['michigan cherries', 'great product', 'ovaltine', '~', 'love it!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_summaries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Преобразуйте ```review_summaries``` с помощью ```TfidfVectorizer```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tfidfed = vectorizer.fit_transform(review_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2641)\t1\n",
      "  (0, 9000)\t1\n",
      "tea greatness\n"
     ]
    }
   ],
   "source": [
    "print tfidfed[0]\n",
    "print review_summaries[2641]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16230 michigan cherries\n"
     ]
    }
   ],
   "source": [
    "f = vectorizer.get_feature_names()\n",
    "print len(f), f[9000], f[2641]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X = tfidfed\n",
    "print type(X)\n",
    "y = train_df.Prediction.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия -- линейный классификатор, который очень часто используется на практике, например, в кредитном скоринге. Преимущества этой модели -- скорость обучения и предсказания (даже при сотнях тысяч фичей) а также интепретируемость: важные признаки имеют бОльшие по модулю веса. \n",
    "\n",
    "При этом отрицательные веса говорят, что фича важна для определения класса 0, а положительные -- для определения класса 1. Это можно понять, если вспомнить, что разделяющая поверхность линейных моделей, это $w^Tx = 0$, а значение алгоритма есть $a(x) = sign(w^Tx)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем предсказывать сентимент, подготовим данные и сделаем валидационную выборку. Вы ведь теперь знаете, что нужно оценивать качество модели не по обучающей выборке, а по валидационной. Иначе вы переобучитесь, когда будете тюнить гиперпараметры модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** Реализуйте код в модуле ```dmia.classifiers.logistic_regression```.**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dmia.gradient_check import *\n",
    "from dmia.classifiers import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой ячейке вы можете проверить, правильно ли у вас все работает, прежде чем обучать модель на всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16230)\n",
      "-1.81172912044\n",
      "-1.93929516206\n",
      "-2.04923002263\n",
      "-1.97963978215\n",
      "-2.10841048539\n",
      "-1.61918861874\n",
      "-2.15004357387\n",
      "-1.80688084633\n",
      "-1.93264717152\n",
      "-2.04114836652\n",
      "-1.32725842771\n",
      "-2.20273948806\n",
      "-2.03872596839\n",
      "-1.95295972398\n",
      "-1.80208444137\n",
      "-1.97223053987\n",
      "-1.95586955622\n",
      "-1.9789034512\n",
      "-2.14048382299\n",
      "-1.65676345675\n",
      "-1.93644378307\n",
      "-2.02737313755\n",
      "-2.35389174893\n",
      "-2.0293350736\n",
      "-2.03336136153\n",
      "-2.07959893478\n",
      "-1.8649080104\n",
      "-1.77155531387\n",
      "-1.95341752647\n",
      "-2.03470284775\n",
      "-2.11222594442\n",
      "-2.21612884369\n",
      "-2.15561784399\n",
      "-1.84106743444\n",
      "-1.73963605352\n",
      "-1.92124319332\n",
      "-2.00580107582\n",
      "-2.12708397477\n",
      "-1.97099382394\n",
      "-1.94184613206\n",
      "-1.97969600386\n",
      "-2.1416324306\n",
      "-2.08157129229\n",
      "-1.90205268913\n",
      "-2.56350776335\n",
      "-1.7768007969\n",
      "-1.63277431946\n",
      "-1.63117723416\n",
      "-2.15721022541\n",
      "-2.21485662965\n",
      "-1.84753294047\n",
      "-2.23280028365\n",
      "-1.82325669043\n",
      "-2.20331165049\n",
      "-2.05660064307\n",
      "-1.96766802654\n",
      "-2.02943582603\n",
      "-1.7819431474\n",
      "-1.77973423813\n",
      "-2.07641059533\n",
      "-1.75542498627\n",
      "-1.75819901934\n",
      "-1.62994457509\n",
      "-2.09423136268\n",
      "-2.07894514287\n",
      "-2.01214403289\n",
      "-1.82047166643\n",
      "-1.92164868652\n",
      "-2.06968961565\n",
      "-2.3220543277\n",
      "-1.69024740092\n",
      "-1.77233589043\n",
      "-2.2704544872\n",
      "-1.97156313413\n",
      "-1.95631668975\n",
      "-1.74598410015\n",
      "-2.1369464001\n",
      "-1.90214222404\n",
      "-1.83567101854\n",
      "-2.19160247174\n",
      "-2.21577251728\n",
      "-1.45845912255\n",
      "-1.93632757831\n",
      "-2.03493951951\n",
      "-1.98297743343\n",
      "-1.83938239819\n",
      "-2.38866482193\n",
      "-1.87432712882\n",
      "-1.70005305177\n",
      "-2.12683973521\n",
      "-1.83616027539\n",
      "-2.02512914463\n",
      "-1.68408458528\n",
      "-1.84179324447\n",
      "-2.34465036396\n",
      "-2.19704419726\n",
      "-2.02796213158\n",
      "-1.84491384349\n",
      "-2.25924489431\n",
      "-1.8058826472\n",
      "[-0.58480317  1.73088113  0.90853968 ...,  2.56304423  3.61394281\n",
      "  1.14973241]\n",
      "(10000, 16231)\n",
      "(10000, 16231) (10000, 16231)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train_sample = X_train[:10000]\n",
    "y_train_sample = y_train[:10000]\n",
    "clf = LogisticRegression()\n",
    "print X_train_sample.shape\n",
    "clf.w = np.random.randn(X_train_sample.shape[1]+1) * 2\n",
    "clf.train(X_train_sample, y_train_sample)\n",
    "print clf.w\n",
    "y_prob = clf.predict_proba(X_train_sample, append_bias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83697379  0.16302621]\n",
      " [ 0.66802825  0.33197175]\n",
      " [ 0.16980945  0.83019055]\n",
      " [ 0.9980445   0.0019555 ]\n",
      " [ 0.96941493  0.03058507]\n",
      " [ 0.47157217  0.52842783]\n",
      " [ 0.16369303  0.83630697]\n",
      " [ 0.29292741  0.70707259]\n",
      " [ 0.08739356  0.91260644]\n",
      " [ 0.87977052  0.12022948]]\n",
      "[[ 0.00148001  0.99851999]\n",
      " [ 0.99515475  0.00484525]\n",
      " [ 0.73438226  0.26561774]\n",
      " [ 0.03888314  0.96111686]\n",
      " [ 0.73305689  0.26694311]\n",
      " [ 0.94285335  0.05714665]\n",
      " [ 0.37316235  0.62683765]\n",
      " [ 0.10524636  0.89475364]\n",
      " [ 0.45285135  0.54714865]\n",
      " [ 0.93789589  0.06210411]]\n",
      "(10000, 16231)\n",
      "(10000, 16231) (10000, 16231)\n",
      "(10000, 2)\n",
      "[0 0 1 0 0 1 1 1 1 0]\n",
      "[1 0 0 1 0 0 1 1 1 0]\n",
      "-2.47101123591\n",
      "-1.81637253024\n",
      "-1.81637253091\n",
      "numerical: 0.000034 analytic: 0.000047, relative error: 1.649638e-01\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: 0.000000 analytic: 0.000037, relative error: 1.000000e+00\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: 0.000000 analytic: 0.000053, relative error: 1.000000e+00\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: 0.000000 analytic: -0.000031, relative error: 1.000000e+00\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: 0.000000 analytic: -0.000056, relative error: 1.000000e+00\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: 0.000000 analytic: -0.000035, relative error: 1.000000e+00\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: 0.000000 analytic: -0.000004, relative error: 1.000000e+00\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: 0.000000 analytic: -0.000015, relative error: 1.000000e+00\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: 0.000000 analytic: -0.000011, relative error: 1.000000e+00\n",
      "-1.81637253057\n",
      "-1.81637253057\n",
      "numerical: -0.000000 analytic: 0.000017, relative error: 1.000000e+00\n",
      "<function <lambda> at 0x7f2ac196d758>\n"
     ]
    }
   ],
   "source": [
    "print y_prob[:10]\n",
    "print y_prob[-10:]\n",
    "y_pred = clf.predict(X_train_sample)\n",
    "print y_pred[:10]\n",
    "print y_pred[-10:]\n",
    "X_b = clf.append_biases(X_train_sample)\n",
    "loss, grad = clf.loss(X_b.toarray(), y_train_sample, 1e-5)\n",
    "\n",
    "# Numerically compute the gradient along several randomly chosen dimensions, and\n",
    "# compare them with your analytically computed gradient. The numbers should match\n",
    "# almost exactly along all dimensions.\n",
    "f = lambda w: clf.loss(X_b.toarray(), y_train_sample, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, clf.w, grad, 10)\n",
    "print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5359\n"
     ]
    }
   ],
   "source": [
    "k = len([i for i in range(10000) if y_pred[i] == y_train_sample[i]])\n",
    "print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4770\n"
     ]
    }
   ],
   "source": [
    "print sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "a = np.ones(200)\n",
    "a = a.reshape((200, 1))\n",
    "b = np.ones((200, 16999))\n",
    "c = a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите свою модель на ```X_train, y_train```.\n",
    "\n",
    "Для начала можете взять параметры по умолчанию, и найти оптимальные используя валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.693514721032\n",
      "-0.692936134143\n",
      "-0.693815014217\n",
      "-0.694301349567\n",
      "-0.694011885955\n",
      "-0.692803463109\n",
      "-0.693303683052\n",
      "-0.69346188\n",
      "-0.6934120936\n",
      "-0.692807613585\n",
      "-0.693137682279\n",
      "-0.693348806152\n",
      "-0.693186886336\n",
      "-0.693225590294\n",
      "-0.693410488479\n",
      "-0.693313001108\n",
      "-0.692899076371\n",
      "-0.692992066241\n",
      "-0.693513877504\n",
      "-0.692851906339\n",
      "-0.694077095946\n",
      "-0.692940263268\n",
      "-0.693098001497\n",
      "-0.693146532994\n",
      "-0.693015272992\n",
      "-0.692491142571\n",
      "-0.692592014136\n",
      "-0.692901074614\n",
      "-0.693003654543\n",
      "-0.693582837948\n",
      "-0.694716969757\n",
      "-0.693417970613\n",
      "-0.693619391946\n",
      "-0.692799493289\n",
      "-0.693885271004\n",
      "-0.69292318525\n",
      "-0.693599182432\n",
      "-0.693626946798\n",
      "-0.69340392104\n",
      "-0.693363281273\n",
      "-0.692968954695\n",
      "-0.693279655024\n",
      "-0.693409978257\n",
      "-0.693230310737\n",
      "-0.693117074456\n",
      "-0.693107024534\n",
      "-0.693315669778\n",
      "-0.693268579451\n",
      "-0.693214195379\n",
      "-0.692896909864\n",
      "-0.693019136749\n",
      "-0.693022459159\n",
      "-0.693128381014\n",
      "-0.69289509746\n",
      "-0.693386236758\n",
      "-0.69254548337\n",
      "-0.693210344163\n",
      "-0.693577555996\n",
      "-0.692620382429\n",
      "-0.69395300005\n",
      "-0.693731131136\n",
      "-0.693621555559\n",
      "-0.692574596721\n",
      "-0.693280870054\n",
      "-0.693255235044\n",
      "-0.693267523056\n",
      "-0.693638439253\n",
      "-0.693942559676\n",
      "-0.692906074425\n",
      "-0.693715993662\n",
      "-0.692473432179\n",
      "-0.693541914351\n",
      "-0.693883515318\n",
      "-0.692607505018\n",
      "-0.692996528757\n",
      "-0.693374832542\n",
      "-0.693421278123\n",
      "-0.693083509387\n",
      "-0.693346930574\n",
      "-0.693630691349\n",
      "-0.693403976208\n",
      "-0.693193470836\n",
      "-0.693968868046\n",
      "-0.693139644534\n",
      "-0.692882177034\n",
      "-0.693258843351\n",
      "-0.693369773\n",
      "-0.693674103774\n",
      "-0.692249413565\n",
      "-0.69304775265\n",
      "-0.693178379531\n",
      "-0.693916487296\n",
      "-0.692958385611\n",
      "-0.692706480632\n",
      "-0.693335249776\n",
      "-0.693081811575\n",
      "-0.693870761567\n",
      "-0.693483332625\n",
      "-0.693043764743\n",
      "-0.692984302581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dmia.classifiers.logistic_regression.LogisticRegression instance at 0x7f49bce9ccb0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77114, 16231)\n",
      "(77114, 16231) (77114, 16231)\n",
      "(77114, 2)\n",
      "Train f1-score = 0.516\n",
      "(33049, 16231)\n",
      "(33049, 16231) (33049, 16231)\n",
      "(33049, 2)\n",
      "Test f1-score = 0.522\n"
     ]
    }
   ],
   "source": [
    "print \"Train f1-score = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test f1-score = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем кривые обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.692972232539\n",
      "(77114, 16231)\n",
      "(77114, 16231) (77114, 16231)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-335c0417f19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Сделайте один шаг градиентного спуска с помощью num_iters=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/MIPT_Data_Mining_In_Action_2016/base/hw01/dmia/classifiers/logistic_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Implement this method. Store the predicted labels in y_pred.            #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m###########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m###########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/MIPT_Data_Mining_In_Action_2016/base/hw01/dmia/classifiers/logistic_regression.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, append_bias)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mW_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0msums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mprob_of_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "num_iters = 10\n",
    "\n",
    "for i in tqdm.trange(num_iters):\n",
    "    # Сделайте один шаг градиентного спуска с помощью num_iters=1\n",
    "    clf.train(X_train, y_train, num_iters = 1)\n",
    "    train_scores.append(accuracy_score(y_train, clf.predict(X_train)))\n",
    "    test_scores.append(accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12e2b3b50>,\n",
       " <matplotlib.lines.Line2D at 0x12e2d4ad0>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAHhCAYAAADNmtINAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XecnWWd///Xfd+nTO8z6Z3kTg8lVANIpEqRFRVdRQQs\n8FW/a1kX9ee6uz91d/36FQuuXbEuCC4gioIU6SRACC2EO72XaZlyppxz7vu+vn/ck0kGUiZkJuec\nmffz8cgDTrnP+czcycz7XNd1fy7LGIOIiIiIHHt2rgsQERERGa0UxERERERyREFMREREJEcUxERE\nRERyREFMREREJEcUxERERERyJHa4J7iuawHfBxYBvcCHPc/bsN/j7wc+A/jALZ7n/bDv/hVAe9/T\nNnqed90Q1y4iIiJS0A4bxIDLgaTneWe4rnsqcFPffXt9A5gDdAOvuq57K1Fgw/O8pUNcr4iIiMiI\nMZipySXAfQCe5y0HFr/u8ReBaqC477YhGj0rdV33ftd1H+wLcCIiIiKyn8EEsQr2TTEC+K7r7n/c\nKmAF8DLwJ8/zOohGx77hed4FwA3Ab193jIiIiMioN5ipyQ6gfL/btud5IYDruguAi4EpQBdR4LoC\n+COwDsDzvLWu67YA44DtB3sTY4yxLOtNfREiIiIix9iQhJbBBLEngUuA37uuexrRyNde7USjX2nP\n84zruo1E05TXAguAj7uuO54oyO081JtYlkVTU+eb+BIk1+rry3XuCpjOX2HT+StcOneFrb6+/PBP\nGoTBBLG7gPNc132y7/Y1ruu+Dyj1PO+nruv+GHjCdd00sB74BVFKvMV13ceBELh27yiaiIiIiEQs\nY0yua9jL6JNBYdKnusKm81fYdP4Kl85dYauvLx+SqUktoBcRERHJEQUxERERkRxREBMRERHJEQUx\nERERkRxREBMRERHJEQUxERERkRwZTB8xERERkcLQ24uzcQMmmcTu7ADLwln1Cs7mjWA74DiYWBR/\nrN5eTHExduNuwslTIJ0By8JuagTbJpg8hXDSJKzmZpxtW7G6u/FnziKYOQsuetuQlKsgJiIiIodl\nNTXhbNwAgKmsJJg+A9Lp6MGysjceEIbRH8vCam/D1NSCMVipTuxNm7AyaaxUitgLz2M37sY/+VTC\n+gYS9/2ZmLcaU15BWFUFiQSO9xrhmLGEY8dh9fYQNoyBdC92ezuxlSuwd+4kmDYdkklizz6DnRre\n/mzGsqKvbQgoiImIiBQIq6kJU14ORUVv/kWMwd65A3vLFuIrV+DPm4/d1Ijd0kwwYRL+wkXYrS04\nq1/F3r2LojvvwCSSxNa8htXTc8CXDMsrMMXFBO5srHQa57XV2B3tmHgck0hid6UIa2qwW1sPXtdP\nfvjmvhzLwtTWknjqCQCCyVPpufydEARgWeA4+PMXRqNYlgW+D4GPZQwmkcRq24Mpr8DetRO7qYmw\nvp5wzFgwIfGXXoRslrBhDKa8HFNejrNhPcHU6VS+qWrfSEFMRETkWMlmSTxwP8GkyfCWxQDEVjxL\n4m8PYaVSBLNcgOiX/fQZZE84iWD2HJxXXqb0m18n+ec/Ymwbf9HxZE86GSudBmOIrXoZU15JdvHJ\n2Lt2QiyO1d2F1dmB1dOLvTu6Dz+L3bgbe8+eIy49rKik5wNXY2WzOFs2Q9bHJBPR7Q3rsdrbSTz+\nKMa2CaZOI6yri4JPPE4IWF1dZGbNhniCsKaGsKEBU16OP28BYf0Yin/5M4jHCaZNJ33hxYQ1tdid\nHVh7WgnHjMXKZrD27MEUFUcjZokEwdTpUUhqaMDeuAFTV4epGKqIBNml5w3Zax2MtjiSo6ZtOgqb\nzl9h0/nLT1bbHuxduwgmT4nWFqU6iT/xGIm/PUTiycf7n5e+5B0k7r0H6xC/i008jpXNAuDPnY8p\nKyP23DNYRzA1FlZXgx+AYxPW1hFMm044aTL+3Pk469eBZRGOH4+9eRPO9u2E9Q34i47HVFTgz19A\nWFOLKS457Eic1d6GSRYd3YhdgRiqLY40IiYiIiNPOh2t4Skujm739GClUljdXVBURFhTC4C9fRvO\ntq1g22BZxJ5ZRvJP92BKSrB37yKcNJmwthYSSejuxm7cjZXNYkrLMCUl0TTe1i04mzZCPAEW4PvE\nVz4fvdcBBJMm42zdAkDyT38AwJSU0H3DJ0k8/ij+nHmkL7uc+LPLKfnutzClpWROO4P0JZeRvuQd\nEI9jb9uK3dqCKS7B3rkDf848Eg/9lcTDD+Bs3UrPR66PRsz8LKaomHDCxGH/lgOYyqpj8j4jiUbE\n5KjpE3lh0/krbAVx/nwfZ9PGKCg89ABhdTXhhEmEY8ZAOo2pqsZubsLq6sKf5RJ75SXiy5/GbmvD\n3rkjmsaLxzElpQQTJxHW1xNb/Sp2WxvB2LFYmQzOxg1YHR2YsjJwnGh6Lgj61voYnF07h+zLMZZ1\nyBEsiEaggqnTsHftInvqaZBIkj3tDPxFx+PPXwjGUG96aF2zOVpkfrARpGwWYrFoik/yikbERETk\nmLF3bMcUFxN7+SWctR5Wdw+xl1+Irl5LJLF6ugnGT4wWOD+zjNjqV8mefApWezvxlSsOvUj7IExJ\nCWSz0dSZbUMYEl/x7IDnxFa9DEAwdhymogKrtwdTVIy/YCEmkcTZsQOAzJKzMNU1mJISrI4O7MZd\nmOISwto6woYGMAYSSYJJk8ie+VZMRUUU4tJpnC2bsbq7CKtrCMeNh1gsuvKvsRF7yybCKVMJJk7G\nbttDWFYevVZxMTjOwb84y4L6sQRO6aG/CfH4EX/fpLAoiImIjFS+3x9k7JZm7J07SDz8AFZnJ+HE\nyZjiYuLLnsRubsZKpwkmTCCcNAV6ezBV1Vg9PdHC7l27cLZsOuK33zv9FkyYSHb+RExVFZ3f/UH/\nCJmzYzv2zh2EVdXRFWm1tdibNxNMnYa/+GRMaTS61d8mwLKIvfwisZXPk7nw7YRl5cRWryKYNAUz\nZswQfuP2U1TUv4B+f6aikqCikuC4mf33hWPGDk8NckiZDOzaZTFpkqGjAx55JMb69TYzZoSk09DV\nZfHXv8bIZGD69JCLLvIJguivVWOjTWOjRUeHxeTJIRs32uzebbFypUMsBmPGhKTTFnZf+/tk0nDC\nCQGzZoV88pNDU7+mJuWoFcTUiByUzl8BMWbgFJXvU79xNZ3PrIxGelpboj5PthOtFVq/DpJFB12r\nBNFC8LBhDDgx7F07sDKZAz4vc9oZWL09BDNmkjn/QkwiSTDLjYLRiy/gbNuKP38B/vwFYFlkTzkN\ne+tWKC4imH7cUH8nRgT924tmXvcf9OvsjAYT9+yx2LXLYvx4Q1GR4fbb42Sz0NZmMX16yOzZIS0t\nFo8/7nD77XF27bKZNClkxw6LIDj6GcPKSkM8bmhutkkkDGEIvr/vdR3H4PtDM1+sETERkWFi7Wkl\n9uILhPUN2C3NOJs2EnvlJWKrX8UkiwiOO46wohIrDLG3bMLZuTNaIF5VhSkqhpISwqoqghkzcbZs\nJvGne7DCABNPQCIBPT3QlaL8IO8f1tWDnyV94bsJZhyHqaoi89a3EY4Zg71tG3ZLczSFV1UdHeD7\nOOvXYYqLo9AHhPUNWD09mNraA75HMHMW6Xe++8CPzRu6NgKSe2EIqVQUhjo7o1GixkaL2bNDGhst\nGhoMNTWGTZtsbr01xs6dNkEAkyeHZDIWM2aE1NQYHnrI4eGHY6TTFnv2WJSUGFw3pLcXVq8+xHTu\nIcyZE7Bpk82JJ4YsXeozZ07Ihg0WjgOlpXDmmT7FxfDssw6rVtmUloJlGRoaoj8A27fbzJ4dMGaM\nYdw4g+NEg8p7Z5iDADo6YO1ah7q6EDhAE9s3QSNictT0qa6w6fztZ+/Pw70LpIPgkGt0opYEj2P1\ndBN/9G9RJ/Bx47Ha9pC8/8/EVr964Lc5zGJvY9tRB/LXPScYOw4rCKC7G4qLMGXlOBecT+echVjN\nTVBcTDBxMqakhHD8hKiBpeStvf/2wjCaXmtutggC2LTJpqQkCgMVFYaKiuj56TT85jdxZs4MWbw4\noLi4v3E9mczAi0QtKxpd6uqyWL7c4aGHYqTT0RSeZUXPq6oyTJ0a9s1gW3R1RUvxSkpgwwaLWCw6\nvq3NYsyYkGefdWhuPvgW1ZZlSCQgnR7cQFFJSfT+r77q9B87dqxh2zaLefNCjjsupLnZYtMmm8mT\nQz74wSy9vbBjh82uXRZFRXDaaQEzZoS47tB0uT8SWqwvInIU7M2bSDzxGPaWTSQefwxn43rslpYB\nz9nbmBLbhmQRhCGmpDh6XjaL1d110MaYJpkkc+Zb8U88KVroXlqKv+gEgnHjo2m7rhRWczN22x4I\nw/6F4Ka6OvqN6jjQ04Pd1Iizfh1hwxiCufPoX6zSp76+nF4F6WMqCA69Dh+iwcrmZouJE82A2eRt\n2yy+/OUkVVWGBQvg/e+H97ynmKeeOvCv45qakF//uoeXXnJ48MEYDz2073mVlYZMBnp6ojcoKjKU\nlBhaW21iMTNgKu3oOVRXG84/36ey0lBebujpsSguNmzfblNWZnjggRi+DxdfnOWii3zGj49GyHbu\ntIjHo9GzrVttxo4NOf30gLo6Q1kZrF0bBa1kMnqn3t5R0Yasn0bE5KhpRKWwFdz5S6fBcYg9v4Lk\nn/9IWFcfhZw58winTMHq6IgWV/f99rN37sBZ4xF//jmcV1cRe+kF7NZW7Pa2g76FP3c+YVUVViqF\nszO66s5qb4tGyTIZwto6LD+L1d6Of/yJZM48i8xFl0AQYO/ejSkrw58zD1NfP+zfjoI7f8PAmCgc\n9e3jTCoFGzdGgbW2NhpV2rzZxrJg+/bo70UsBh0dFk884ZDNwvTphurqaD1SGEZTWD09FvG4YcUK\nh61bbU48MaClxcLzbKZNM4wdGzJlSsj69TaZTLTgu6XFoqzM0Npq0d1tUVlpOP74gOpqwxNPOPT2\nWqRShw9I11yT4a674rS1vfG5H/hAho0bo0XmEE0V1tWZAdN6paWGOXNCxo0LmTEj5NJLferrDa+9\nZjNlSkhdnWHbtmhkqaQE4nFDMgmplEVbG0ydaggCGDcupLg4CpV1deaQAcn3o88QicRgz1xhG6oR\nMQUxOWr6RVDYhuT8ZTJRr6bNm8CysJsaib38ImSyhGPH4mzdErUiSKcx5RUEc+ZGe9Ht2oF/4smQ\nyURrn4qKia14tu/5pcReeoHYqpcJZrrRViq9vcReW42JxbB8/6Dl+NNnYCorMaVlxJ9dHm0D08fY\ndjRtN2UqmfMuJGxoILP0XExNLVZLC6am5sA9m4Kgv+lnvzB8wwjVsTaS//2lUrB5s82YMQbfh5YW\ni1mzQmwb7r8/xrp1Np2dcNddcbZssSktjUZqGhstwnDoRoOKigyxWBRS9k6neZ49YFF4cXEUUurr\no2A2frxh3ryA557bN51XVxcSj8OYMVGdL70Uo6IipKHBcMMNGS66yOcvf4kxe3bIrFkh2Sx8+9sJ\nXnnFZs6ckKlTQy6+2Kf8IIsCN2yIpvF27bK48EKfmpoh+xbIASiISd4Yyb8IRhprTyuxlStwtm7F\nnz0X/5RTqc900LKnm3DsuOhJvb3En10Ovo/d3oa9exfZk04mtsbr77nkrF0TPbZ1K/FlTxJ78YXD\nNrh8M4zjEE6aHHUtJwpR/vEnYKUz+HPnEUyYSDBvPlZrK87GDTjr1hBbt7b/+RD1oup9xzvJnn0O\n2dPfQlhdM6LmPY72318qRd/C5cEfs2cPrFzpsHp1FEbe+lafJ55wWL/epqHBcOaZAU884XDmmQHr\n19ts3Rot1F6/3uaxx2Ikk6Y/07a1ReGmvDxav9TZaTF1aogx8Nhjb5yuKy011NdHC8L3KioyLFwY\n0NNj0d5uMW5ctGbI92H3bpuODotp00KSScPkydF7+z4kEoZTTglwHNiyxaa7G5qbo5GzM8/0qaoy\n9PZGbQ2Ki6MgWFUVhbKeHujstFi3zmbhwoCy/dZt9/ZGSwv3Lvbevt2itdVi/vxwwJJD/ewsbApi\nkjf0w2QYdHVhdXVhSkuxsplo2xDLihZwt7dFt7PZ/v3r7D17sBt3R/eFIWSz+AsWRlNraz2cLZuj\nvk0b1vfvWQcQTJkajWIBwfgJmMoqnA3rBowgDUZYXQ1OjLCiguzpb8FUVOLPmYupqMTZvhUTTxDW\n1mJ1dWE3NWG3tuC7szF1dSTvuA1TXBLV291DMHUq/rwFxDauJ7vwhGh6L5OJRqSCgAG/8Q4mk4lG\n5lqaMWVlmLKDXVdY+Gpry1m2rItEwpBKWSQSMGNGNGrU1RWFLIC2Nvjzn2M89liM5uYo/DQ12axY\n4VBZaZg7N6C72yKZjNb+nHhiwIYNNtu22TiOoaMjuq+31+KRR4ZveXF1tWHPnuj3W319yJIlAalU\nNEVYXAxPPeWwc6fNFVdkueQSn95eWLrUp7p62EoaNvrZWdgUxCRv6IfJETCGxEN/pegXP4v2frMs\nrLY9xF5+CZMsIpw4CXvbVmKvvTpg6i0YNx6Syf6RnrCsHDt1ZN/zsKKSYPp0sm85i2DadBL33Uvy\nwb/CWWeRjieJvboqamcwey7+CSdhb99KMG8BwbTpxJY/DYkkYW0NdlMTgTsb48TwFywimD0bU6E2\nBUPBmGjhcns7vPRStDjacaL71qyxaW212LnTwnVDHnkk1pfNLVKpga9TUmLo6YkemzQpJBaLFoln\ns2/8vTFhQkhREaxff/Ap1mTSUFtr2LEjes6YMSHveU+WmhpDNhuNClVVGS64wOfhh2OsWmVz2mkB\nmzdHi8aXLg1YscJm926bf/mXNDU10Tqs1laL2lpDd3c0BTl7dkgiEY3StbREDTpfP/MbhtGIU0nJ\nUX+7c04/OwubgpjkjVH7wySTGbAq1d6yOfpNmow2B7ayWayO9mhxeEcHsZUriL366mE7lJtYjGDa\ndIIpU7HSaUwiQfzFF7Cbm4Bow2CrK4WpqMTevYved70Xf9Hx/fvxWb09mLJy4g8/iKmpIXvaGQST\np2CqD7D2qbeX+kn1o/P8DbNMBnbvjhZwOw7MnBmyfLlDJgNbt9ps2WKxZo1NV1e0eLu52WL3bmvQ\nl/7vVVUFS5dm+1sXNDdbvPKKTSIRTb21tkZtCMaPN1x8sc9FF/lMnhz1bMpkogXYlhWFmzCEZcuc\nvtE0iwkTQhYuDPsv4ly50qalxeLss4NRsyB7OI3an50jhIKY5I3R9MPE3rWT2LPPUPzzH5N48nGC\nMWPpvebDxFauIHn/Xw57fFhWTuZt59H7oeswyST4AeGECTibNhLW1GLvacWfNz8KTfszJvqz/1CA\nMVG/q6P8jTiazt+R2LDBIgyjoOM4hnTaorra8OijDt3dFr4P3d0WW7daLF4cANDUZNPWBvfdF+OF\nFxwymX0/pwfTTqCqyjBzZnSl2ymnBNh2FOgmTYrWRU2YELJ5c9Qkc9GigNJSGD9e569Q6d9eYVMf\nMZEh5qx+lcRf/xKtzSqvoOi/f0U4dhw9134UgOQf7yL5p3v6pwxNcTHO7l2U/udXAcjOX0g4bTr4\nPiYej66+y2YxtXX4CxaSOe0t0XqnA1xlF06aDEBwsOIsK/qz/3yMZY2e68SHQE9PNFi599vv+9F0\nnefZZLMW69fbPPecw9NPO8TjhpaWN56nkhJDd/fgfvYed1zAokUhVVWG5maLRx+NMWuWz9lnB5SX\nR60FJk2KHs9mLerr3zgNdyCTJh30b4mIFCAFMRk1nLVrMPE4JBLEVq/Cam+P+lG99CKxl18k8cjD\nbzxo/ToSTz7ef9OfM4/ed76LYNZsMmefQ/K+e6O9+saMwz/5lCO79EyGVUuLRXc3bNtm87vfxfjd\n7+IkEtEUW319tCD8QD2aIOoxNWNGSH19tOg9CKI1VKWlcPbZWebNi9ZdOU7UkHLNmmiUqrw86oZe\nVWU466zgsE0/98mbmQkROcYUxKQwGYO9dQuWnyX2/ArSf/cuAKw9e7D8LIn7/0LiwfvJnr6EzNJz\nSTz4V0q/9q/R9jAHkT3pZDJnn0MwdRqmtAxnwzqC6cdFmyjHYviLjid7xpIBYetge+yNZrt2RWud\n9q6JSiajHqxTp4Z0dlrMnRv2N948nL0rJ/Z+y42B9vZo892WlmgUK5uNgtLatTbLljl0dloUFRme\neWbgm1RWGsaPj7ZBWb/eJh6Hc87x+7aKMYwdazj11ICnnnI455ygf/85EZHhpDVictSOyTqHbJbE\nX/6Ef/KpxJ9ZRumXPo+ze1f/w6a4GHx/QGuGA77M8ScQ1tbhn3wqYVU1dkc7YcMY/Fku/kknj5oR\nrb1bKVrWoc/fhg0WpaXQ0BBtU9LQEF3h1tJi8cILDnffHaOpyaa5OWp7sHu3fdBRpr3mzAm49tos\n5eWG8eMN06dH/Z56eqI1V1H/KIcwtPjtb+M0NVmcc46P59mkUlb/lXuHc8IJ0RRgSYnhIx/Jcvrp\nwYDO65a1r7VDIdM6o8Klc1fYtEZMCldvL6Vf+zfstj30XPdRgklTMLW1A59jTH8oKvv0J0jedy92\nSwvGtqM+Wa8TTJiIqaggbBiD1d2Dv2Ah2ZNPpeSbX8cKQ3refxWZSy8nHDP2WHyFObE3XGzeHF2R\nd9550WLvvfu2pdPRti8335zg7rtjHHdcyJVXZunuhkwmgTGwa5fN44871NYaSksNy5dHPyIcxwzo\nIr4/y4qacXZ0RAGposJw+ukBTU0WU6aEjB9vsCzD+vU2jY1R36rPfW5wc3bJZFTHH/8Y73+vsWND\ndu2yWbLE58wzA5LJqMdVRYVhyZKAiRNDmppsZs0KD5qrB9OKTETkWNCImBy1w32qc1a/SulXvox/\n4mJ6rvsoVZdfTGz1qgHP8WccRzBnHlZXCnp6om1pggDjOP3TidmFx+Ps2IaJxen4+a/xF58yILAV\nqt7e6Mv4n/+J09UVjT6l01H7gEwGLrjAZ8cOm4qKaPrs0UcdHn88RkdHtOXKtGkhGzbYPP20M+Cq\nvDlzAlpbLXbvtt8QpIqLo/cYzDYwrhv1g+rtjfbQW7w4oKgouorv4x/PMG1a1P5g2bIoXC1cGBy0\nx5MxsHy5w+bNFlu22GzeHLVDSCQMJSXRQvqODotTT/WprTWcf35AImHYuNFm7txoy5e+wc9BT2+O\ndBpVKVw6d4VN7Sskb7z+h4m9dQvxZ5aBbRNf/jTFP/9J/2P+zFnE1q6JOqevehkg6rje2nrILXLa\n/uePZM88u+CDV1cX3HFHnDvvjNHVZfVtfTI0exVWVxtSKVi4MGTjxoGvO39+QF1ddFXeW9/q8773\nZWlrs1ixwmHs2GK6urrZtMmmrMwwf360p53jRNu07N2SxRj6+0lJ/tAv88Klc1fYNDUp+SMIKPrV\nLcQfewRn+1ZiK58/4PQhQGztGjLnvI32X/8O4nEc7zUCdzZWczOl//5v+PPmE8x0IZmMtsiJJ7A7\nO/ZNKRZgCAtDWLXKpqcH/umfinj11SjJxOOGKVNCpk0LWLEiuu8f/zGN40QjVnV1hpdfjkaPXDek\nqyvqYD5hQhSS3v52n0WLQp5/Ptq/7/rrM9TVGRKJaPH6tm0WEyeag44cVVYapkzxqa+HpqaAQzTP\nAKJvvUKYiMjQ0oiYHFDs5Rcp+uUt+AsWRlvcvPwSVmc7zrZtmOISgkmTyC45i2D6DOq+fCPcdlv/\nsf7sOTibNhLMmEn60neQectZ+KeehtXSgpXuJRw/IYdf2dG57bYYf/5zjC1bbEpK4Ec/6mHiRMMz\nzzisXGlz770xnnvOYe7ckMsv91m5MrqSr7l53+jUhRdm+dSnMsycGVLetwXiww87jB9vmD37wAF2\nOOlTeWHT+StcOneFTVOTMqRizy7HlFdEexA+9jfKP/Ex7D17Bn189tTT6bj5h4QTJ0WLd17fdyDP\nvH6Gs2+fbJLJ6IrArq5oe5rmZpuLLvLZts3iG99Icuut8QGvE48bjOGQHdNra0POPTcglYLOTotf\n/rInr67W0y+DwqbzV7h07gqbpiblzctkiK1ehb/weLAsnA3rqL74PCDa59Dq6wzfc9WHCKYfh71r\nJ/5JizGOQ/zZZ8iechpWNkP88UdxNm8mce45tH3wowN7AeQ4gHV0wJ49FlOm7Pug8cgjDqmUxZ49\nFl/9apKFCwMuu8zn6acd/vrXGB0dFrGYIQiizZL3mj8/YPVqmyCIFpX/13/1smRJwDe/meBnP4sz\nY0bIrFkhZ54ZcMklPhs22Dz8cHTl4eLFAQsWhCSTufguiIhIvtOI2GgShhT9968p/skPiK1+lZ6r\nr8NfuIjyz/7vfU+pqyd94dvpvfpa/EUnDOplj/WnumwW7rknxpNPOjQ3R/2sZswIaW2NNk4+4YSQ\nJ56I9gMsKTEsXerztrcFfPrTRYN6/bq6kNmzQ5Yt23cVYk1NyPXXZ/nIRzID8mY2u28xe6HSp/LC\npvNXuHTuCpumJuXIpFKUf+5TFP3P7Qd8OKyrZ89fH4nWbw1mw7v9vJkfJs3NFjt2WCxYcPBeT/sz\nBu6+O8amTTaeZ3PnnW9MP8lk9Hc5nbaoq4v6V7300sDV5ddemyEehw99KIPvW/zmN3GOOy7kqquy\nbNtmMWGCGbAgPZOJRtYaGkyuB/mGjX4ZFDadv8Klc1fYNDUpg2K1tJC8+/eU/Oj7OJs2kl14PF3/\n9jX8BQspufnb2Dt30PPhj+Eff+Ixq6mx0eKss0pobbVZuDBg9uyQiRNDPvvZDGvX2sRi8PGPF3Hh\nhT5XXpnlv/87zh/+EGPt2n0Jqbzc8E//lGbBgpAFCwK2bo0aeNp2dIXilCkhFRXwq1/FeeihaJud\nU04JuO667H6ByvCVr6T7X3Py5Dd+KEkkYMyYvPmwIiIiI4xGxEYYq7MDe+dOsCxKvv41kn/6Q38r\nie4Pf4yuL/0bB+22+SYN5lPd5s3RVjmVlYaPfrSIe+898vm8M87waW+3GDfO8K1v9SogDRF9Ki9s\nOn+FS+eusGlETAbq6+VVfuNnBt49fgI9H/s46QsuIpw+45iU0tkJmYzFvffGqKoyrFtn85//Ga1W\nX7LE54kFD0gnAAAgAElEQVQnYsyfH/Dtb/fyf/9vgosu8vn1rxM891w04nXSSQFnneXz29/GaWyM\n+mb9/vfdzJih4CUiIiOLRsQKSGzlCpL33A22TfrCtwMQ1jdg9fZSedWVOJs3DXh+16f/kZ5PfhpT\nVj6sddXXl7N2bSe/+U2cjRttbr89Tjp98A8Kc+YE/PGP3VRU7LsvCODJJx1mzgwZN27f38l16yxq\nagw1NcP5FYxu+lRe2HT+CpfOXWHTYv1RJPHXv1D6H1/t3xLoYIKGMfR+6DrSF1+G3dpC9i1nHvF7\nRb2zok7uDz7oMHWqYcaMkK4uqKqK1ne1tVk4jmHq1Ghh+9at5VxwQdjftHTMmKhdQ28vTJxomDgx\nZO7ckNNOCygrM8ydG2qfwDyiXwaFTeevcOncFTZNTY5UmUy0Qhwgm6X0K/9CyQ+/h3Ec/HkL6P7E\nP4AxxJ97BqulBWfHdmIrnqXnIzfQ9ZX/6H+Zg21Ws2KFzd13x7niiiwLF4a0t0NlJVx5ZTEtLdGV\njAfb+7Cy0tDevu/v3ZgxIe99b5bbbouaoH7uc2nOPjvadieZLPhtIUVERIadRsTyhLPqFco/+0li\nK58n/c534y86nuLvfQencTf+tOl0/uQXUQPWA7BSnYedftyxw+Jvf4vxxS8m6ekZmI7q6sIBW/Ds\nNX58SH294cUXo7VbEyeG9PbC9OkhJSXwyCNRjo/F4Ctf6eW667Jv5kuXHNOn8sKm81e4dO4Km0bE\nCpS9bSvxp58k9sLzJB57BKuzE7ttD1Z3NwAmkYh6ffX1++r5+6vo/qcvHnJ/xkOFsK1bLe66K853\nv5ugoyP6O/Pud2fp7IT7748xfbqhs+/nwFVXZXjHO3zGjw8pLob6ekM8HrWDmD174HRiEMB3vpMg\nHodPfjIJKISJiIgcKQWxY8RqaaHo97dR+h9fxeru6r/f2DamuIRw0mQ6v/EtsqeeQfKB+yj+r+9i\nystJ3XTzETVY3bDBYvt2m+OOC/nLX2L88z8nyWajADZzZsBnP5vhne/0Aeju3tfJIggY0Mh0f/Pn\nv3EjaseBz3wmA0B9fZKmpkGXKCIiIn0UxIabMZR9/rMU3/LT6Kbj0HP1dWRPWkz6794VJRrLihZU\n9Q05pS+/gvTlV0Q7Ub8uhDU2WqRSsGOHzde+luTcc6Omp+vX2/yf/5Pk2WcHpqmKCsOnPpXmgx/M\nvqHv1v7txA4WwkRERGT4KIgNo+Stv6H8C5/D6u7Cnzad9DvfTe8HriacMHFwL2DbfP3rCW67Lc55\n5/ksX+6wevXAxLRihcPXv75vR+lx40LCMBrhuvrqLFdemWXq1LxZBygiIiL7URAbBvHHH6X0a/9K\n/PkVAKQvvZzUv36VcNLkNzz3tddsbropwfXXZ5g40dDQsC803XNPjG9+MwpZv/hFdCVlImGoqTHs\n2mVz8skBvg8rVzosWeJzww0ZzjorIBaLgtjeiy9FREQkPymIDbHYiyupuuJSAPwZx9Hx898QzJl7\nwOcGAXzqU0U8/7zD3XfHicUMp54acOKJAQ8+GOsf/frJT3qYNCkkk7Gorw8ZM8bw2ms2J5wQ4jjR\nWq/i4oGtIjTVKCIikv8UxI6S1dyMKSmBkhJiy5dR9qUbAcicdQ7et/6H+x4qZmZrSCJhGDvW9Ld8\nmDs34Pbb4zz/fJSYTjwx4PnnHZ58MsaTT+47LZ/+dJrLLvPf0I9r8eJ9C+iHeOtIEREROUYUxI5C\n8Q+/R9mXv0hYU0PmbeeTvOcurHSa9EWXcM/Vt3L1ktI39Ox6vdmzA/70p2i7n+5u+MhHinnggRjn\nnefzgx/0DNgGSEREREYWBbE3KbbiWUr/5f8DwG5tpeiO2whLy2j74S/4SePl3PQPCXp7oaTEMH58\nyK5dNrYNF17o84c/xEinLd75zixf/nK6P2yVlMBvf9ujjvQiIiKjhILYm5FKUfavX8IyhrY7/4TV\n0018+TK6r/8Ef3hqLDfeWATApz6V5otfjHpt+X7UoSIeh+9979AvrxAmIiIyOiiIHUZs+TLKb/wM\nHd/7EVa6F1NWTsVHryG2ehVN517BNT87nw98IMvCj13Erf8d5zvfiS5V/NnPerj0Un/f6+g7LSIi\nIq+jeHAoxlD2xc8Re/UVapa+ZcBD3R/6MDeam7n3l3HuvTfOtGkhGzdGzVff+97sgBAmIiIiciAK\nYgdiDLEXnif+3DPEX37xDQ/3Xvn3fNe9mVu+UNR/38aNNpMnh1x3XYb3vlf7LoqIiMjhKYi9XhhS\n+v9/mZLvf7f/rsySs0g88RgATVub2N2W5N/PSFJVZbj99m6uuqqY0lK4885uxo9XF3sREREZnMHv\nJj1KFN/8rQEhrP3MC/nNOT/CT5bQ/qvb2NpYxEUXldLZafGJT2Q4/viQF1/s4umnuxTCRERE5Iho\nRGx/vb2UfOcmwvoGWh95mvizy/nQbRdz91cqaP56M1ec4XPBaSU0N9t85CMZbrghuiLSVpwVERGR\nN0FBDLA6O0je8Ttia17DTnXSffW1mPp6Nh1/KXd/qAyA//qvJDfeWAzANddk+OpX02ozISIiIkdl\n1Aex2LPLqbjmAziNuwEwxcX0vvf9APzgB/t2zd6yZd+w1w03ZBTCRERE5KiN6km1+LKnqLrk/P4Q\nBtB5080E7my2bbO49dY4dXUhF1+87yrIp59OMXWq1oKJiIjI0RvVQSx55x1YxtD1uS/Q8syLdPz4\nFrrf8W5uuSXO6aeX0tFh8fGPZ/o31a6rC5kxQyFMREREhsaonZp0vNco+u2vCCsq6f705yAWIz11\nGt/4zwQ33ZQE4EtfSvO//leWdesCHn/c4Qc/6M1x1SIiIjKSHDaIua5rAd8HFgG9wIc9z9uw3+Pv\nBz4D+MAtnuf98HDH5IOiX/0cK5ul6X9/lj0dMTZutHnggVh/CLvssiyf+ES0FmzmzJCXXurKccUi\nIiIy0gxmROxyIOl53hmu654K3NR3317fAOYA3cCrruveCiw9zDE5F3v5JRqtBk7+3RfZ8k1nwGO3\n3dbN0qVBjioTERGR0WIwa8SWAPcBeJ63HFj8usdfBKqB4r7bZhDH5JbvE1v1Cj+uuZEt2waGsC99\nKa0QJiIiIsfEYIJYBdC+323fdd39j1sFrABeBv7keV7HII7JqeTvf0fY2cVtwXuIxQwPPNDFr37V\nzQUX+Fx7bSbX5YmIiMgoMZipyQ6gfL/btud5IYDruguAi4EpQBfwW9d130UUwg54zKHU15cf7ilH\nJwzBsuDO3/E9rmdV20Te9z4499xSAK66CgaWLYM17OdOhpXOX2HT+StcOncymCD2JHAJ8HvXdU8j\nGvnaq51obVja8zzjum4jUNV3zGUHOeagmpo6j6T2I5NKUXn1+0g8/igAfyj/D+iEz38+RVOTWlIc\njfr68uE9dzKsdP4Km85f4dK5K2xDFaIHE8TuAs5zXffJvtvXuK77PqDU87yfuq77Y+AJ13XTwHrg\nF0AAnL//MUNS7VGom38cVnc3AD0U8UTvycydGzBunEKYiIiI5MZhg5jneQa44XV3r9nv8R8BPzrA\noa8/Jmes9rb+EAbw8Bmfp/cph7PP1nowERERyZ1R0dDV2bQRgO4Pf4zsW5fyl8cvhqfg7LP9HFcm\nIiIio1neXMk4nJyNUS/ZlnFz2XnS23nkiSKSScNpp6lNhYiIiOTOyA5ixkAqRdEtPyXE4qJffpA5\nc8pYtcrhlFOC/j0kRURERHJhxE5NWp0dVL7n74iveBaAK+seYNWWKgBqa0M+/WmtDxMREZHcGplB\nrLubyr9/d38ISyfKuKPlbQD87Gc9LF3qU1qaywJFRERERmgQK/75T4gvf5rey/6OzPkX4o07C3OF\nxZVXZrn0Ui3QFxERkfwwIoNY8s47MPE4qW98C1Ndw/qHov0kJ08+bHN/ERERkWNmxC3Wd9Z4xF95\nicw5b8NU15BKwfveF63KVxATERGRfDLigljyzjsASL/z3aRScN99+wb9FixQEBMREZH8MbKmJoOA\n5F2/x5SU8OOWK/jc9H37QN15Zzdz5yqIiYiISP4YOSNixlD+8Y8S27iBxvPfyz9/paL/oc9+Ns2S\nJWreKiIiIvllxIyIxZYvo+jOO8iedDI/mf9Neu+2uPrqDJdf7vOWtyiEiYiISP4ZMUEs/swyAFLX\nf5Kf/3sFyaTh85/PUFtrclyZiIiIyIGNiKlJq7OD4l/8FID70+ewcaPNFVdkFcJEREQkr42IIJa8\n/VacbVtJv/1Sfv+3MQB86EPZHFclIiIicmgjIogl/vYQAG3/8h88/HCM8eNDFi3SFZIiIiKS30ZE\nEIu99CLBxEnc8cx09uyxuPhiH8vKdVUiIiIih1b4QSwMsZsa2VU/ny9+sYhEwvCxj2VyXZWIiIjI\nYRV8ELNaW7GCgAfN2+jstPiHf8gwebIW6YuIiEj+K/ggZjfuBmBZ+gQAzjnHz2U5IiIiIoM2IoLY\nbhq4c8vJlJQY7ScpIiIiBaPwg1hTI5dxD41d5Vx7bYZkMtcViYiIiAxOwQex2BqPtcwk7oR84Qta\npC8iIiKFo+CDmPPoI7RRxUknZonHc12NiIiIyOAVdhDLZul6cSMGm6rawv5SREREZPQp6PRi79jO\nHlMFQHV1josREREROUIFHcSc7dtopQaAqir1DhMREZHCUtBBzN62lT1EQ2EKYiIiIlJoCjqIOdu2\nakRMREREClZBBzF78yaaqAcUxERERKTwFHQQi61fx9PWGQDMm6eO+iIiIlJYYrku4GjY69fzN/tt\nNNSGzJypICYiIiKFpWBHxKyOdta01LIraGDJkgDLynVFIiIiIkemYIOYvXs3f+McAN7yliDH1YiI\niIgcuYINYlZLC89zIgAnn6wgJiIiIoWnYIOY3drCGmZhWyHTpml9mIiIiBSegg9iU2o7SSZzXY2I\niIjIkSvYINa5s5PdjGXGhJ5clyIiIiLyphRsEGva5gMwbpymJUVERKQwFWwQa2uMglhVQzzHlYiI\niIi8OYUbxHZnAKgcV5TjSkRERETenMINYs3RiFi1RsRERESkQBVmEDOGttbof7XZt4iIiBSqggxi\nVmcHrZkyAKqrFcRERESkMBVkEHM2bqCVGkAjYiIiIlK4CjKIFd/8bVqoBRTEREREpHAVZBCLP/cM\n2xLTsCxDQ4OCmIiIiBSmwgti3d04O7azxZrK2LGGRCLXBYmIiIi8OQUXxJzNm/Bx2JZpYMIEjYaJ\niIhI4Sq8ILZxAzsZR2AcJk3S9kYiIiJSuAouiNmNu3mJhQBMnaogJiIiIoWr8IJYcxN3czkA55wT\n5LgaERERkTev8IJYSzOPcjaVZT4nn6wgJiIiIoWr4IJY965O1nEc8+dkcJxcVyMiIiLy5hVcEHt1\nawUGm/mLCq50ERERkQEKLs2sb6oE4Dg3x4WIiIiIHKXCCmLpNC1N0f/W16uHmIiIiBS2ggpi8WeW\n0exXAVBXp9YVIiIiUtgKKojFXnyBRhoAqKvTiJiIiIgUtoIKYlaqgybqAaitVRATERGRwlZgQSxF\nE/XEYyEVFbmuRkREROToFFQQa22B5zmR2mofy8p1NSIiIiJHp6CC2G3eSWRIcu5ZvbkuRUREROSo\nFVQQa0/FAbjiXX6OKxERERE5egUVxLp6YwCU1iRyXImIiIjI0SuoIJZKR0GspFQLxERERKTwxQ73\nBNd1LeD7wCKgF/iw53kb+h4bA9wGGMACjgdu9Dzvx67rrgDa+15mo+d51x1tsd19Qay0VK0rRERE\npPAdNogBlwNJz/POcF33VOCmvvvwPG83cA6A67qnAV8FfuK6brLv8aVDWWwqmwQUxERERGRkGMzU\n5BLgPgDP85YDiw/yvJuB6z3PM0SjZ6Wu697vuu6DfQHuqHX5RQCUlAzFq4mIiIjk1mCCWAX7phgB\nfNd1Bxznuu6lwCue563ru6sb+IbneRcANwC/ff0xR6ynhy5TTNzKktBafRERERkBBjM12QGU73fb\n9jzv9TtufwD49n631wDrADzPW+u6bgswDth+qDeqry8/+INb9pCijNJ45tDPk5zQOSlsOn+FTeev\ncOncyWCC2JPAJcDv+9aBvXyA5yz2PO/p/W5fCywAPu667niiILfzcG/U1NR58EK9jaSYRGk8Q1PT\n63Og5FJ9ffkhz53kN52/wqbzV7h07grbUIXowQSxu4DzXNd9su/2Na7rvg8o9Tzvp67r1jFw6hLg\nZ8Atrus+DoTAtQcYRTsidnMTXcymqsgfZNkiIiIi+e2wiaZv8f0Nr7t7zX6PNwMnvu6YLNF05ZCx\nmptJUcaEkq6hfFkRERGRnCmYhq5mdzPdlFJSmutKRERERIZGYQQxY+j6y1MAVNfmuBYRERGRIVIQ\nQczZsI625zcBUD2tMrfFiIiIiAyRgghi9rZtNFMHQF19josRERERGSKFEcR2bKeJKIHV1mp7IxER\nERkZCiKIOQpiIiIiMgIVREMua/sO/pHvAlBToyAmIiIiI0NBjIitW2fRRRkAkyapq76IiIiMDAUR\nxLZvdwA480yf447TiJiIiIiMDIURxJoTALzrXdkcVyIiIiIydPI/iHV1sb0n6uI6frxGw0RERGTk\nyPsg5uzcwTYmAgpiIiIiMrLkfRCzt21lK5MAGDdOC/VFRERk5Mj7IOZs3sQ2JlJZnKasLNfViIiI\niAydggli4xsyuS5FREREZEjlfRDrXr+LdqqYMCnvSxURERE5Inmfbnau7QZg3NR4jisRERERGVr5\nHcR6e1mzIeohNnmKrpgUERGRkSWvg1js1Vd4OjwVgMWLgxxXIyIiIjK08jqIxZ96kmWchmOHHH+8\ngpiIiIiMLHkdxJL33sNq5jBtSkBpaa6rERERERlaeR3E2l/dSSu1zJhl5boUERERkSGXv0Gsu5u1\nPdHWRtOnq6O+iIiIjDx5G8Ts1hZeYzYAM2YoiImIiMjIk79BrKWZl1kAwJw5WqgvIiIiI0/eBjGr\npZmXWAjAnDkaERMREZGRJ2+DmN3czCrmMaW6XZt9i4iIyIiUt0EsbGxlN2MYX5/OdSkiIiIiwyJv\ng1jrpg4MNvUNua5EREREZHjkbRBr2dQDQP3ERI4rERERERkeeRvEmnZkAKibXJTjSkRERESGR/4G\nscaoNE1NioiIyEiVn0Esm6WxIxoJq683OS5GREREZHjkZRCzOjtoJBoKq69XDzEREREZmfIziKVS\n7GYMoBExERERGbkUxERERERyJK+DWFm8l5KSXFcjIiIiMjzyNIh1spsxNJR25boUERERkWGTl0HM\ndKZoop76ip5clyIiIiIybPIyiKVaswTEqKnwc12KiIiIyLDJzyDWEnXVLy9V6woREREZufIziO2J\nRsLKKnJciIiIiMgwys8g1haNhJVXWDmuRERERGT45GUQ62yPglhZlZPjSkRERESGT14GsVRn9N+y\n6lhuCxEREREZRnkZxDq7orLKauM5rkRERERk+ORpEIumJMtqEzmuRERERGT45GcQ646mJMs1NSki\nIiIjWH4GsXQ0ElZWnuNCRERERIZRngaxJABlZTkuRERERGQY5WUQS2X6RsTKTI4rERERERk++RfE\njCHlFwEKYiIiIjKy5V8Qy2RImVIASkpyXIuIiIjIMMq7IGalUnRSTrGdJqaLJkVERGQEy8Mg1kmK\nMsrivbkuRURERGRY5V8Q6+iIglgik+tSRERERIZV3gUxu6OdTsopTWZzXYqIiIjIsMq7IEZbezQi\nVhLkuhIRERGRYZV3Qay3pYsQh9ISta4QERGRkS3vglhPUzegrvoiIiIy8uVdEEu1pAEoLbdyXImI\niIjI8Mq7INa1J7pasqzKyXElIiIiIsMrD4OYD0Bplbq5ioiIyMiWd0Gsuz26WrKkOp7jSkRERESG\nV94FsVRXVFJZTSLHlYiIiIgMr7wLYl09UUmlFXlXmoiIiMiQOuxCLNd1LeD7wCKgF/iw53kb+h4b\nA9wGGMACjgduBH5ysGMOp7M3mpIsLT3Cr0RERESkwAxm2OlyIOl53hnAF4Cb9j7ged5uz/PO8Txv\nad9jK4hC2EGPOZyu9N4gpoauIiIiMrINJogtAe4D8DxvObD4IM+7Gbje8zxzBMe8QWcmWhtWVqYg\nJiIiIiPbYIJYBdC+323fdd0Bx7mueynwiud56wZ7zMF0ZZOApiZFRERk5BtMOOoAyvc/xvO88HXP\n+QDw4yM85o2MIeUXARoRExERkZFvMF1TnwQuAX7vuu5pwMsHeM5iz/OePsJj3qC+qoiUiYbCpkwp\no75+MEdJPqivLz/8kyRv6fwVNp2/wqVzJ4MJYncB57mu+2Tf7Wtc130fUOp53k9d161j4DTkAY8Z\nTDHNm3fR2TeQ1tvbSVPTYI6SXKuvL6epqTPXZcibpPNX2HT+CpfOXWEbqhB92CDWt/j+htfdvWa/\nx5uBEwdxzGFZ3d2kKMOxApLJIz1aREREpLDkVddUq6ebTsopj/diWbmuRkRERGR45VcQ6xsRK41n\ncl2KiIiIyLDLqyBGdw+dlFOWVBATERGRkS+vgpjV3UWKMsqS2VyXIiIiIjLs8iqIBZ099FJMWbGf\n61JEREREhl1eBbGutmgkrLT48L1fRURERApdngWxaCSsrERBTEREREa+/Api7QEApaXa3khERERG\nvvwKYh3RSFipdnwQERGRUSC/glhnNBJWWp5XZYmIiIgMi7xKPKlU9N+yCrXVFxERkZEvr4JYV1cU\nwEornRxXIiIiIjL88jOIVcdzXImIiIjI8MurIJbqiUbCSqsUxERERGTky6sg1tUTA6C0JpHjSkRE\nRESGX14FsVQ6GgnTGjEREREZDfIriGWiIFamPmIiIiIyCuRXEOvtGxErzXEhIiIiIsdA/gQxY+hK\nR2vEysq0xZGIiIiMfPkTxFIpOsNoKKykJMe1iIiIiBwD+RPEmptJUUaJ04ujtfoiIiIyCuRPEGtq\nop1KyhKZXFciIiIickzkVRDbQzVVJelcVyIiIiJyTORNEDPNLbRRRVW5n+tSRERERI6JvAliXZ0h\nPnEqS7K5LkVERETkmMibINaWilpXVJVqjZiIiIiMDnkTxPZ0RkGsslQjYiIiIjI65E8QS0Vd9atK\ntUZMRERERoe8CWJ7pyYryxTEREREZHTInyDWFY2IKYiJiIjIaJE3QSyTtQBIJLTPpIiIiIwOeRPE\ngiD6rxOzcluIiIiIyDGSN0HM75uRVBATERGR0SLvglgsriAmIiIio0PeBLEgiNaGOQpiIiIiMkrk\nTRDz/SiAaWpSRERERov8CWJ7F+trRExERERGibwJYnuvmtQaMRERERkt8iaI7ZuazJuSRERERIZV\n3qSeQFOTIiIiMsrkTRDzg74RsUTelCQiIiIyrPIm9fQHMU1NioiIyCiRN6knCKP/ampSRERERou8\nCWJ+EJXixPOmJBEREZFhlTepZ+/UZCyhETEREREZHfImiPVfNZlwcluIiIiIyDGSN0HMD6NSbC3W\nFxERkVEib1LP3sX6MbWvEBERkVEib1LP3hExBTEREREZLfIm9ey9atJWEBMREZFRIm9STxD2NXRV\n+woREREZJfIm9eydmnQSsRxXIiIiInJs5F0QiyXzpiQRERGRYZU3qad/alJ9xERERGSUyJsg5pu+\nqcmYOuuLiIjI6JA3QSzYOzWpJWIiIiIySuRNEPNDG4sQO28qEhERERleeRN7fGPjEOS6DBEREZFj\nJm+CWGBsYvi5LkNERETkmMmbIOaHjkbEREREZFTJnyBmbGKWgpiIiIiMHnkTxDQ1KSIiIqNN3gQx\n3zg4VpjrMkRERESOmbwJYtGImKYmRUREZPTImyDmG0drxERERGRUyaMgFsNREBMREZFRJG+CWICu\nmhQREZHR5bA7O7quawHfBxYBvcCHPc/bsN/jJwPf7Lu5C/iA53kZ13VXAO1992/0PO+6Q72PFuuL\niIjIaDOYLbYvB5Ke553huu6pwE199+31Y+AKz/M2uK57LTDFdd0tAJ7nLR1sIT4xBTEREREZVQYz\nNbkEuA/A87zlwOK9D7iuOwtoAT7juu4jQI3neWuJRs9KXde933XdB/sC3CEFxlYQExERkVFlMEGs\ngn1TjAC+67p7j6sDTge+C5wLnOu67luBbuAbnuddANwA/Ha/Yw4oQFOTIiIiMroMZmqyAyjf77bt\ned7exPT/2rvXWEuvsg7g/73PtLUMpzXKqUKiKE18jIk2WpQWe7GkDdogYuIXtERqi9oQ4yVeqAYT\nY7AmCpFqQGUC1ktKtEmNkbQNooRhGlGxxjbqmpYqHxBDHeyFEqTtHD/sPc7ppHPOmWbmvGuzfr8v\nM+9t9jp55uz932utd71HkjzUWjucJFV1dxY9Zu9M8lCStNYerKojSV6c5FMne5FnspZ986PZ2Fg/\n2Sl0TN1Wm/qtNvVbXWrHboLYoSSvSXJHVV2S5P4txx5O8sKqetlyAv/lSQ4kuSHJNyd5c1W9JIsg\n9+ntXuRo5pnnaB555Inn8WMwpY2NdXVbYeq32tRvdandajtdIXo3QezOJNdU1aHl9vVV9fok+1tr\nB6rqhiS3V1WS3Ntau6uqzkryvqo6mORokh/Z0ov2nJ7JWuazzef/kwAArJgdg1hrbTOLeV5bHd5y\n/MNJXnHCNU8lue5UGvJM9mVtLogBAOPoZkHXJCbrAwBD6SqIzfWIAQAD6SuImSMGAAykqyBmjhgA\nMJK+gpgeMQBgIH0FMT1iAMBAugpiM0EMABhIV0HM0CQAMJK+gpgeMQBgIIIYAMBE+gpia1O3AABg\n73QVxCzoCgCMpK8gtiaIAQDj6CqIrXXVGgCAM6ur6GOyPgAwkq6C2Lyr1gAAnFldRR93TQIAI+kq\niOkRAwBG0lX0WXPXJAAwkL6CWFetAQA4s7qKPnNzxACAgXQWxGZTNwEAYM90FcQMTQIAI+kq+li+\nAvJgy5sAAAm3SURBVAAYSVdBzBwxAGAkghgAwES6CmKGJgGAkXQWxNw1CQCMo6sgNt83dQsAAPZO\nX0FsrkcMABhHV0HMHDEAYCRdBbH5Pj1iAMA4ugpia+aIAQAD6SqIzT3jCAAYSFfJx0O/AYCRdBXE\nDE0CACPpLIjpEQMAxtFVEJsZmgQABtJVENMjBgCMpLMg1lVzAADOqK6Sj5X1AYCRdBXELF8BAIyk\nsyA2dQsAAPaOIAYAMJGugpi7JgGAkXQVxMwRAwBG0lUQWxPEAICBdBXErKwPAIykqyBmaBIAGIkg\nBgAwka6C2Kyr1gAAnFldRZ/5WlfNAQA4o7pKPoYmAYCRdBXE1vZN3QIAgL3TVRCbzfWIAQDj6CqI\nzT3iCAAYSF9BzGR9AGAgXSUfk/UBgJF0FcRmhiYBgIF0FcQMTQIAI+kq+bhrEgAYSVdBbL6vq+YA\nAJxRXSWf+drULQAA2Dt9BTE9YgDAQLpKPpavAABG0lUQm+kRAwAGsuNjtqtqluRdSS5K8oUkN7bW\nHt5y/NuTvH25+V9Jrkvy1HbXnMxsLogBAOPYTfJ5XZJzWmuvTHJzkneccPz3k7yxtXZFkruTvHQX\n1zx3Y0zWBwAGspsgdlkWASuttY8lefmxA1X1DUmOJPmZqvpwkq9orT243TXbNsbQJAAwkN0kn/OS\nPLZl++mqOnbdi5JcmuTWJFcnubqqrtrhmpM3xsr6AMBAdpwjluTxJOtbtuettaPLvx9J8lBr7XCS\nVNXdWfR+PbbNNSd1wVefl/O/cjdNojcbG+s7n0S31G+1qd/qUjt2k3oOJXlNkjuq6pIk92859nCS\nF1bVy5aT8S9PciDJJ5J870muOanPPvpkvnhUr9iq2dhYzyOPPDF1M3ie1G+1qd/qUrvVdrpC9G6C\n2J1JrqmqQ8vt66vq9Un2t9YOVNUNSW6vqiS5t7V21/JOy2dds5vGeNYkADCS2ebm5tRtSJLMZtn8\n5CefyLnnTt0STpVvdatN/Vab+q0utVttGxvrp6X3qKtxQMuIAQAj6Sr6CGIAwEi6ij5rFnQFAAbS\nVRCbmasPAAykmyA2y1FBDAAYSjdBbJ4d13sFAPiSIogBAExEEAMAmIggBgAwkY6CWB8r/AMA7JV+\ngthMjxgAMJZ+gpihSQBgMIIYAMBE+gliM3PEAICx9BPE9IgBAIPpKIjpEQMAxtJPEHPXJAAwmH6C\nmB4xAGAw/QQxPWIAwGD6CWJ6xACAwfQTxPSIAQCD6SiI6REDAMbSTxAzNAkADKafIGZoEgAYTDdB\nbE0QAwAG000QM0cMABhNP0HMHDEAYDD9BDE9YgDAYDoKYuaIAQBj6SiI6REDAMYiiAEATKSfIGay\nPgAwmH6CmB4xAGAwghgAwEQEMQCAiQhiAAAT6SeIzQUxAGAs/QQxPWIAwGD6CWIvOHfqJgAA7Kl+\ngtg31dRNAADYU/0Esfls6iYAAOypboLY/v1TtwAAYG91E8RuuWXqFgAA7K1ugtiFF07dAgCAvdVN\nEAMAGI0gBgAwEUEMAGAighgAwEQEMQCAiQhiAAATEcQAACYiiAEATEQQAwCYiCAGADARQQwAYCKC\nGADARAQxAICJCGIAABMRxAAAJiKIAQBMRBADAJiIIAYAMBFBDABgIoIYAMBEBDEAgIkIYgAAExHE\nAAAmsm+nE6pqluRdSS5K8oUkN7bWHt5y/KeS3JjkM8tdP9Zae7CqPp7kseW+f2+t3XBaWw4AsOJ2\nDGJJXpfknNbaK6vqFUnesdx3zMVJ3tBau+/Yjqo6J0laa686nY0FAPhSspuhycuS3J0krbWPJXn5\nCccvTnJzVR2sqrcs912UZH9V3VNVf7UMcAAAbLGbIHZejg8xJsnTVbX1utuT/HiSq5JcVlXXJnky\nyW+01l6d5KYkf3LCNQAAw9vN0OTjSda3bM9ba0e3bL+ztfZ4klTVB5J8a5IPJvlEkiznix1J8uIk\nn9rmdWYbG+vbHKZnarfa1G+1qd/qUjt200t1KMm1SVJVlyS5/9iBqjovyQNV9YLlpP5XJfl4khuS\nvH15zkuyCHKfPr1NBwBYbbPNzc1tT9hy1+S3LHddn8W8sP2ttQNV9UNJfjKLOyo/1Fr7lao6K8n7\nkrw0ydEkv9Ba+9sz9DMAAKykHYMYAABnhgn0AAATEcQAACYiiAEATGQ3y1ecMTs9Pok+VNW+JO9N\n8nVJzk7ytiT/kuQPsrgZ44HW2puX574pyY8meSrJ21prH5igyTyHqrogyT8kuTrJM1G/lbFcLPu1\nSc7K4j3zI1G/7i3fO2/L4r3z6SRvit+9lbBciP7XW2tXVdWF2WXNqurLkvxxkguyWP7rh1trR7Z7\nral7xP7/8UlJbs7i8Un057ok/91auyLJdyf5nSxq9YuttSuTzKvq+6rqq5L8RJJLl+fdsryDlokt\nPxB+N8nnl7vUb0VU1ZVJLl2+T35Xkq+N+q2Ka5Ostda+M8mvJvm1qF33qurnkrwnyTnLXadSs5uS\n/PPy8/KPkrx1p9ebOojt9Pgk+vCnOf6faS2Lb3bf1lo7uNx3V5JrknxHko+21p5eLvL7YI4ve8K0\nfjPJu5P8Z5JZ1G+VvDqL9Rr/PMlfJPnLqN+qOJxk33L05/wsek7Urn8PJfn+LdsX77JmF2VLrlme\ne/VOLzZ1ENvp8Ul0oLX2+dbak1W1nuTPkvxSFh/mxzyRRS3X8+x6fi6LNx8mVFVvTPKZ1toHc7xu\nW3/P1K9vL8pi7cYfyPKRcVG/VfG5JF+f5N+S/F6SW+O9s3uttTuz6HA45lRqtnX/sXO3NXXo2enx\nSXSiqr4myV8nua219v4sxsqPWU/yaBb1PO859jOt65NcU1V/k8U3tj9MsrHluPr17UiSe5bfvA9n\nMZ9264e0+vXrp5Pc3VqrHP/dO3vLcbVbDbv9vPufPDvX7KqOUwexkz4+iX4sx8LvSfLzrbXblrvv\nq6orln//niQHk/x9Fg9+P7uqzk/yjUke2PMG8yyttStba1e11q5K8k9J3pDkLvVbGR/NYg7KsUfG\n7U/yoeXcsUT9evbZHO8deTSLG+TuU7uV84+n8H55b5a5ZvnnwRP/sRNNetdkkjuz+KZ+aLl9/ZSN\n4aRuTvLlSd5aVb+cZDOLx1r99nJy4r8muaO1tllVt2bxwTHLYnLjF6dqNNv62STvUb/+Le/Euryq\n/i6LutyU5D+SHFC/7v1WkvdW1UeyuOP1LVk8j1ntVsuu3y+r6t1Jbquqg0n+N8kP7vSPe8QRAMBE\nph6aBAAYliAGADARQQwAYCKCGADARAQxAICJCGIAABMRxAAAJiKIAQBM5P8Az1sNRyS7rIwAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13aafeb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(train_scores, 'r', test_scores, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Задание\n",
    "\n",
    "* Обучите вашу модель **на всех данных**, преобразовав их через ```TfidfVectorizer``` с ```max_features=3000```.\n",
    "\n",
    "* Параметры модели ```learning_rate=1.0, num_iters=1000, batch_size=256, reg=1e-3``` и выведите первые 5 самых важных фичей для класса 1 и 5 фичей для класса 0. Убедитесь, что они коррелируют с вашей интуицией о хороших/плохих отзывах. \n",
    "\n",
    "\n",
    "* Топ позитивных фичей перечислите через запятую под пунктом 1 в письме с кодом.\n",
    "\n",
    "* Топ негативных фичей перечислите через запятую под пунктом 1 в письме с кодом.\n",
    "\n",
    "\n",
    "**Hint:** зная индекс фичи, само слово вы можете получить, используя метод ```vectorizer.get_feature_names()```.\n",
    "\n",
    "**Hint:** ```np.argsort```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обучите модель\n",
    "clf = LogisticRegression(learning_rate = 1.0, num_iters = 1000, batch_size = 256, reg = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Получите индексы фичей\n",
    "pos_features = ...\n",
    "neg_features = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Выведите слова\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение с sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите такую же модель, но из пакета ```sklearn.linear_model``` и убедитесь, что ваша имплементация ничем не хуже (ну или почти не хуже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.924\n",
      "Test accuracy = 0.896\n"
     ]
    }
   ],
   "source": [
    "print \"Train accuracy = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test accuracy = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Что дальше?\n",
    "* Нам повезло, что классы в нашем датасете сбалансированы. Какие проблемы возникнут у логистической регрессии, если, скажем, будет 90% нулевого класса и 10% первого. Как нужно изменить код, чтобы исправить эту проблему? Постарайтесь придумать не менее 2х способов.\n",
    "* Почему мы не делаем регуляризацию для bias term в весах? Может, все таки, в каких-то случаях ее стоит делать?\n",
    "\n",
    "Ответы на вопросы напишите здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "<h1 align='center'>Part 2: Boosting</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "Самый простой метод минимизации функции, для оптимизации в каждый момент времени двигаемся по антиградиенту функции с каким-то шагом. \n",
    "\n",
    "\n",
    "$$w_{n+1} = w_n - s \\cdot \\frac{\\partial f}{\\partial w}$$\n",
    "\n",
    "### Градиентный бустинг\n",
    "\n",
    "Теперь давайте представим, что на каждом шаге мы оптимизируем не параметры алгоритма $w$, а ответы нашего алгоритма $\\hat{y}$.\n",
    "\n",
    "**Обучение**: На каждом шаге, давайте предсказывать градиент на каждом объекте и \"двигать\" ответ в сторону улучшения (антиградиента).\n",
    "\n",
    "**Как в итоге обучать**:\n",
    "- Первый алгоритм отвечает константу \n",
    "- Добавляем базовые алгоритмы $b_i$, $i = 1, .., N$:\n",
    "    - Вычисляем градиент функции потерь ПО ОТВЕТАМ модели $g_{i-1} = \\frac{\\partial L(\\hat{y},~~y)}{\\partial \\hat{y}} = \\frac{\\partial L(\\sum_{j=0}^{i-1} a_j b_j(x),~~y)}{\\partial \\sum_{j=0}^{i-1} a_j b_j(x)}$ на каждом объекте  \n",
    "    - Обучаем $b_i$ предсказывать текущий $g_{i-1}$\n",
    "    - Подбираем $a_i$ -- одномерной минимизацией \n",
    "    - Дополняем композицию $\\sum_{j=0}^{i-1} a_j b_j (x) + a_i b_i(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** Реализуйте код в модуле ```dmia.classifiers.binary_boosting```.**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dmia.classifiers import BinaryBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from dmia.utils import plot_surface\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=2,\n",
    "                           n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=2,\n",
    "                           flip_y=0.05, class_sep=0.8, random_state=241)\n",
    "y = 2*(y-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-95f3ba4c55f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_surface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/MIPT_Data_Mining_In_Action_2016/base/hw01/dmia/classifiers/binary_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, original_y)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_feature_imps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/MIPT_Data_Mining_In_Action_2016/base/hw01/dmia/classifiers/binary_boosting.pyc\u001b[0m in \u001b[0;36m_calc_feature_imps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m### YOUR CODE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf_imps\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "clf = BinaryBoostingClassifier(n_estimators=100).fit(X, y)\n",
    "plot_surface(X, y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAHcCAYAAACXlKD2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGEhJREFUeJzt3Xu0l3WB7/HPb7MBJQER74ACKU9aTWhOXstpnC5OTulq\nMC/VSctOt7HS9GSz6ngs7ebySGpTU2PHSltFZenS7KbjSVZ5tKuWPl4wSdEEkaty2Xv/zh8QqaOi\nm833+fHbr9c/8GyB/Vks3G+e7/Nj71a73Q4AUE5P0wMAYLgRXwAoTHwBoDDxBYDCxBcACust9p7m\nzPGyamCj5mRW0xNgSMyaldbT/Td3vgBQmPgCQGHiCwCFiS8AFCa+AFDYoF7tXFVVb5KLk0xNMirJ\n2XVdXzmEuwCgaw32zvfNSRbVdf2KJIcnuXDoJgFAdxvsv/P9VpI567/fk2Tt0MwBgO43qPjWdf1o\nklRVNTbrIvyvQzkKALrZoF9wVVXVlCTXJrmkrutvDt0kAOhug33B1U5JfpjkvXVdXze0kwCguw32\nme8ZSbZN8tGqqj6WpJ3k8LquVw/ZMgDoUoN95vuBJB8Y4i0AMCz4JBsAUJj4AkBh4gsAhYkvABQm\nvgBQmPgCQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgC\nQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCF\niS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+\nAFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+AFBYb9MD\nALrVimUP56FvnJGxyx/Osr1fkemHn5xWq9X0LDqA+AJsJgtnH5PTb/lJWknuu/mKXNoakemHv6/p\nWXQAx84Am8GqVSvyoj/+Jn+5z5080Jdt6rmNbqJziC/AEOjrW5tVq1ZuuB41akweGLfDhuv+JMse\nd83wJr4Am2jeVbPTPnmPbPe+qblt9nHp7+9LT09PVrz5M/nilBfl8m13yWf2fV0mH3dO01PpEJ75\ndojf/HFhzr1yVdb2jcqxB6/JkS+b0vQk4FlY/PB92e/bZ+awlUuSJK+c+42cN3Vmqjecnl1fekTa\n+74uq/rXZo/eUQ0vpZOIbwdYvHxFjj1/bG5f8J4kyU9vvSETx/4qL99rl4aXARuzfOG9qdaHN0nG\nJBm99KEN161WK73Cy5M4du4A1/5+QW5f8IYN1w8vPyQ/+u2jDS4Cnq2dp+2TK6fuu+H6F9tMyKiZ\nr2lwEVsCd74dYO9J4zN2q9uyfNX+SZJWFmfK9gMNrwKejdGjx+SxD307n/3u2Rm9dlX69n9jpvzN\nq5qeRYcT3w6w95Sdcuas/8wF19yRNX1b5/X73ZaTDquangU8S9vuOC3bvuvLTc9gCyK+HeKUf5qe\nD7xuIP0DazOy9wVNzwFgMxLfDtLT05OeHo/hAbqdj/QAUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHi\nCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUtknxrapq/6qqrhuqMQAwHAz6qxpVVXVakrckWTF0cwCg\n+23Kne9dSY4aqiEAMFwMOr51XV+epG8ItzBMLF35aN520d057Kwlee+X78jqtWubngRQ1KCPnWGw\n3v6FB/KdG09P0pNrb12TgfZn828nzWh6FkAxQ/Fq59YQ/BoMI3+4b1L++kdvVG67b+cm5wAUNxTx\nbQ/Br8EwMmXiw4+7amfSxEWNbQFowiYdO9d1fW+Sg4ZoC8PEBSeOyXv/4/zMX7R9ql0X5Py37dj0\nJICiPPOluBm7TsiPPzph/dW0RrcANMFnuAKAwsQXAApz7Ayw3sBAf+64/qtpr1ySyS8/PmPHez0C\nm4f4AiRpt9u54/xj84FfzMk2Sb503Vey9CNXZ/zEyU1Pows5dgZIct+8X+VNN34nY7Pukxec9Kdb\nsuiHFzU9iy4lvgBJWq3Wf/mkBQMtn0OIzUN8AZJMmrZPvnng0VmSZCDJF3Z/SXZ67b80PYsu5Zkv\nQNbd+VYnX5qLXnpE+lY8kt0OPjbbjJvY9Cy6lPgCrNfT05MZLz++6RkMA46dAaAw8QWAwsQXAAoT\nXwAoTHwBoDDxBYDCxBcAChNfAChMfAGgMPEFgMLEFwAKE18AKEx8AaAwX9UI6CizMmfQP3dOZg3h\nEth83PkCQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgC\nQGG+qhHQtR66//YsfeDOTNr7FRkzZnza7Xbuvur8bP2nW/PoLjPy/Neflp4e9yCUJ75AV5p35Xk5\n5Nv/K3s9tixXTNo7i075Vhb/7Ot51/c+nYlpZ2mSC5Y8kOpt5zc9lWHIX/mArjMw0J/J11yQgx9b\nlu2SvO3+P+Sx7386u/zh+kxMO0kyPsnk237W6E6GL/EFus7AQH+2XrvqCW8b1bcmK8aMf8LbVj7p\nGkpx7AyFzMmspicMG729o/L7fY/I31/75WybZO42E7PmoGMyertJ+dLiBZm5oM4tu+yR/qPPbHoq\nw5T4Al1pxju/mIum7ZPeh+/LVjNfkyl7H5ok6fvUTbl5yZ8zfvyOGTtydMMrGa7EF+hKPT09mfGa\n9/yXt/f2jsr2209pYBH8lWe+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgC\nQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCF\niS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+\nAFBY72B+UlVVrSSfT/KSJKuSvKOu63lDOQwAutVg73yPTDK6ruuDkpyR5LyhmwQA3W2w8T0kyTVJ\nUtf1jUn2G7JFANDlBhvfcUmWPu66r6oqz48B4FkYbDCXJRn7+F+nruuBIdgDAF1vsPGdm+Qfk6Sq\nqgOS3DJkiwDoCAMD/bnjklOy7GMvz58+e2QW3183PalrDOrVzkkuT/Kqqqrmrr8+YYj2ANAh7ppz\nVt5/1f/ONuuvZy9dmHxi7jP+HJ6dQcW3rut2kncP8RYAOsj4+2/bEN4kef4Dd2bJ6kczevSYxjZ1\nCy+SAuApLd1xalY/7vqPO+6eUaO2bmxPNxnssTMAXW76MZ/IucsWZbd7fpklY7dPz/GfTqvVanpW\nVxBfAJ5Sb++ozHjPxUmSnRve0m0cOwNAYeILAIU5doZCZmVO0xOekzmZ1fQE6FrufAGgMPEFgMLE\nFwAKE18AKEx8AaAw8QWAwsQXAAoTXwAoTHwBoDDxBYDCxBcAChNfAChMfAGgMPEFgMLEFwAKE18A\nKEx8AaAw8QWAwsQXAAoTXwAoTHwBoDDxBYDCxJeu09ffn7f/2+2p3r86+3/k4VzzmwVNTwJ4gt6m\nB8BQO+fyu3PxdacmGZMkef9XvprffnZNtho1qtlhAOu586XrzF+4Tf4S3iSZv2ivLFy2rLlBAE8i\nvnSdl05/LL09fz1qfuGUm7LLhAkNLgJ4IsfOdJ13vXp6ljx6Sa69dWLGj1mZj79p6/SOGNH0LIAN\nxJeu02q1csZRe+SMo5LEHS/QeRw7A0Bh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+AFCY+AJA\nYeILAIX59JJ0rDV9ffnc1XdnxaoROe6QCZmx68SmJwEMCfGlI/UPDOSoz96dq399WpLR+frPvpXv\nn74oL5yyfdPTADaZY2c60u/uvT8/+PUxSUYnSe7+89H5P//pa/IC3UF86UhjRo/MyN7Hx3YgI0f0\nN7YHYCiJLx2p2nXnvOPvr87IEXckWZoD9pydD/3Trk3PAhgSnvnSsS56R5XjDrkiDy1dk9fus3u2\nHjWq6UkAQ0J86WgHv2D3picADDnHzgBQmPgCQGHiCwCFeeZLYy6/cX6++n+3zoie/vzL4QM5dG+v\nZgaGB/GlET+vH8w7//1lWbT85UmSm+d9L9ef+VB232FCw8sANj/HzsNUveDhHHP+/BzxqYcz++q7\ni7//a29dviG8SXLvwiPy4989UHwHQBPc+Q5Da/r6cvznBvLLeacmSX7yu3sybus5OeGV04ptmLHr\niIwc8aes7Z+SJBm79e/yN7ttW+z9AzRJfIeh+xcvzm/vPXjD9eq+afnFnSNzwivLbZh14PT8ct4l\nmfPzaekd0Z93/sOCvGzP55cbANAg8R2Gdhw3LpO3uy1/XDhz/VsezeSJK4vv+NTxVT55XDvJyLRa\nGw/vylWrcu/Ch7PbDhOzzVZbbf6BAJuJZ77D0PO22irnvfXBzJz675m+42V56yvOyxlH7tHIllar\nlVartdEfd8NtD+alH27nhae+Nvuc3pOf3rKgwDqAzcOd7zB11P6Tc9T+f7mqmpzyrJz1nVbqBW9N\nktz14Avy8e98Poe9uOFRAIPkzpctwopVY57xGmBLIr5sEQ578YKM6HkwSdLTWpjDXnRfw4sABs+x\nM1uEs46ekUkTvpLfzR+dvSatyvteO6PpSQCDJr5sEVqtVt716mZeFAYw1Bw7A0Bh4gsAhYkvABQm\nvgBQmPgCQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvHa/dbudX8+7L\njXfOz8DAQNNzoFGPrlyS+obLcl/986ansAl8PV862sDAQN56YZ1vzH1TBtojc+TfXpo5p+yZ3hEj\nmp4GxT3y4N1pnXtUTpl/S+4ZuVW+f8Qp2fPYs5uexSBs0p1vVVVHVVV16VCNgSf79o135bIb3puB\ndpVker5306m5+Lo7m54FjVhy5bk5af4tGZPkhWtXZZ8ffzErVy5pehaDMOg736qqzk/y6iS/Gbo5\n8ESPrOhLO+Mf95ats+yxdmN7oEkj+/uecD2mb036+tY0tIZNsSl3vnOTvHuohsBTOeagqdl32heS\nrAvuCyf/R44/ZFKzo6AhI155Qq7abnKSZFmS6/d7fcaN26HZUQzKRu98q6o6MckHs+6jX2v9tyfU\ndT2nqqpDN/M+hrnxzxuTH3ykP7Ov/mQG2q2859XbZ5cJ4zf+E6EL7VIdlHs/fGU+edMVGRi/Q6p/\n+O9ptVpNz2IQNhrfuq4vTnJxgS3wlHYcPzZnHzu26RnQEXaYOjM7TJ3Z9Aw2kX9qBACFiS8AFLZJ\n/863ruvrk1w/RFsAYFhw5wvQoHbbP50bjsQXoAF9fWtyx+zj0vfeaVly2szcf9MVTU+iIJ9eEqAB\n93z7rHxo7jcyOkkW3Zuvfu3UrJ35mowcObrpaRTgzhegAdssXpDHZ3bPRx7IihWLG9tDWeIL0IDH\n9jwg944YueH6xt1enPHjd2xwESU5dgZowPRXvTOXrV6RCbdel+VjxmX8sWenp8dX6xouxBegIXsc\ncUpyxCmZ2PQQinPsDACFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQ\nmPgCQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBhvU0PgOei3W7ngh/cnZvnbZPJ\n2y3PmUdPy6hef4yBLYuPWmxRzvnuXfmfc05M/8DOSVbn3kXn5tKTZzQ9C+A5cezMFuVnt09cH94k\nGZ0b75za5ByAQRFftijbPm/5E66322b50/xIgM7l2JktyjnHjsv8Refn9/fNzKQJ8/KJY1Y3PQng\nORNftijTd5qQuR/fNouW350Jz3teekeMbXoSwHMmvmxxWq1Wdhg3rukZAIPmmS8AFCa+AFCY+AJA\nYeILAIWJLwAU5tXOAAyZh+75ddZccW5G9q3JqoOPye4HvLHpSR1JfAEYEiuWL87Y2cfmrQvqJMnP\nf39t/t+47bPr3oc2vKzzOHYGYEg88Ifr84b14U2SA1cszmO//VGDizqX+NIx+vr7m54AbIJxk1+Q\nW8eM33D9cFpp77B7g4s6l2NnGvfgI8vzlgsX5/d/2j2TtluYz50wkAOrnZqeBTxHO03aKzfMOjN3\nXXNhxvStzu37HpHqsJOantWRWu12u8x7mjOn0DtiS/OWC+7J1392WpJWkuSgGZ/P3E/s0OwoMiez\nmp7AFqrdbmdgoD8jRgzv+7tZs9Z/UHsKjp1p3MJl45PH/Rn989LxT/+DgY7XarWGfXg3Rnxp3H7T\nFyVZsv6qPzOnzm9yDsBm568mNO6sN+2R3hGfz2/vnZBdJyzJZ948uelJAJuV+NK4np6enHn0nuuv\ntm90C0AJjp0BoDDxBYDCxBcAChNfAChMfAGgMPEFgMLEFwAKE18AKEx8AaAw8QWAwsQXAAoTXwAo\nTHwBoDDxBYDCxBcAChNfAChMfAGgMPEFgMLEFwAKE18AKEx8AaAw8QWAwsQXAAoTXwAorLfpAQCU\nd9/NV2Srq87PqP61eWj/N2aP132g6UnDivgCDDOPLJyfGV96d173yIIkyW3zfpWrd5ye3f729Q0v\nGz4cOwMMMw/d+fMcuj68SbLXmkez9u6bGlw0/IgvwDCzw/Nflrnjd95wfdeordI7dWaDi4Yfx84A\nw8x2O03LrSd+Ln+8enZGr12dBw745+xxwBubnjWsiC/AMLTbgbOSA2clSfZoeMtw5NgZAAoTXwAo\nbFDHzlVVjUvy9STjkoxMcmpd178YymEA0K0Ge+d7SpKf1HX9d0lOSHLRkC0CgC432BdcnZdk9frv\nj0zy2NDMAYDut9H4VlV1YpIPJmknaa3/9oS6rn9ZVdXOSb6W5OTNuhIAushG41vX9cVJLn7y26uq\nenGSy7Luee8Nm2EbAHSlwb7gau8k30pydF3XtwztJADoboN95ntOktFJZldV1UqypK7ro4ZuFgB0\nr0HFt67rI4d6CAAMFz7JBgAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+AFCY\n+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+AFCY+AJAYeIL\nAIWJLwAUJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAU\nJr4AUJj4AkBh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4\nAkBh4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+AFBYb9MDGL7mZFbTE7rerMxpegLwFNz5AkBh\n4gsAhYkvABQmvgBQmPgCQGHiCwCFiS8AFCa+AFCY+AJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkv\nABQmvgBQmPgCQGGtdrvd9AYAGFbc+QJAYeILAIWJLwAUJr4AUJj4AkBh4gsAhYkvABTW2/SAZ1JV\n1ZgklyWZkGR1kv9W1/UDza7qPFVVjUvy9STjkoxMcmpd179odlVnq6rqqCT/XNf18U1v6SRVVbWS\nfD7JS5KsSvKOuq7nNbuqc1VVtX+ST9V1/cqmt3Sqqqp6k1ycZGqSUUnOruv6ykZHdYBOv/M9KcnN\ndV0fmuTSJP+j4T2d6pQkP6nr+u+SnJDkombndLaqqs5PcnaSVtNbOtCRSUbXdX1QkjOSnNfwno5V\nVdVpSb6UZHTTWzrcm5Msquv6FUkOT3Jhw3s6QkfHt67r2Vn3QTJJdkvySINzOtl5Sb64/vsjkzzW\n4JYtwdwk7256RIc6JMk1SVLX9Y1J9mt2Tke7K8lRTY/YAnwryUfXf78nydoGt3SMjjl2rqrqxCQf\nTNLOujuSdpIT6rr+ZVVVP03yoiSvanBiR9jI79POSb6W5OQGJ3aMZ/i9mlNV1aGNjutc45Isfdx1\nX1VVPXVdDzQ1qFPVdX15VVW7N72j09V1/WiSVFU1NsmcJP/a7KLO0DHxrev64qx7LvBU/+2wqqqq\nJFcl2aPosA7zdL9PVVW9OOuej59a1/UNxYd1oGf6M8XTWpZk7OOuhZdNVlXVlCTfTXJhXdffbHpP\nJ+joY+eqqj5cVdWb11+uTNLX5J5OVVXV3ll3tHNcXdc/anoPW7S5Sf4xSaqqOiDJLc3O2SJ47cAz\nqKpqpyQ/THJ6XdeXNL2nU3TMne/TuDjJJVVVvT3r/qJwQsN7OtU5Wfeij9nrX626pK5rz6IYjMuT\nvKqqqrnrr/0/t3G+NNwzOyPJtkk+WlXVx7Lu9+vwuq5XNzurWb6kIAAU1tHHzgDQjcQXAAoTXwAo\nTHwBoDDxBYDCxBcAChNfACjs/wO6yJduZkMeuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13b7d4310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outliers_indices = clf.out_\n",
    "plot_surface(X[outliers_indices], y[outliers_indices], clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы обучали логистическую регрессию на 1000+ фичах и это было быстро.\n",
    "\n",
    "Как вы думаете, разумно ли обучать бустинг над деревьями на 1000 фичах? А на 10000? 100000? Обоснуйте ответ в каждом случае. Если не разумно, то что можно предпринять?\n",
    "\n",
    "Ответ напишите ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BinaryBoostingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ccc5deea0b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Train accuracy = %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Test accuracy = %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BinaryBoostingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "clf = BinaryBoostingClassifier(n_estimators=100, max_depth=3).fit(X_train, y_train)\n",
    "\n",
    "print \"Train accuracy = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test accuracy = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Посмотрим на ```feature_importances_```\n",
    "\n",
    "* Обучите бустинг **на всех данных**, обработав ```review_summaries``` с помощью ```TfidfVectorizer``` с ```max_features=1000```.\n",
    "\n",
    "* Параметры модели возьмите ```lr=0.1, n_estimators=100, max_depth=3```.\n",
    "\n",
    "* Найдите топ-10 самых важных фичей с точки зрения алгоритма.\n",
    "\n",
    "* Перечислите эти 10 слов через запятую под пунктом 3 в своем письме с кодом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryBoostingClassifier(lr=0.1, max_depth=None, n_estimators=100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidfed = vectorizer.fit_transform(review_summaries)\n",
    "\n",
    "clf = BinaryBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "clf.fit(tfidfed, train_df.Prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_imp_features = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Напечатайте слова\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение с sklearn.ensemble.GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите градиентный бустинг из ```sklearn``` и сравните его качество на ```X_test``` с вашим (Оно не должно отличаться на много процентов! Вы образали деревья?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Train accuracy = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test accuracy = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
